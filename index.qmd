---
title: "CEVE 543 Fall 2025 Lab 6: Julia Climate Data Tools"
subtitle: "YAXArrays.jl, NetCDF.jl, exploring CMIP6 data structure"
author: CEVE 543 Fall 2025
date: "2025-10-17"
type: "lab"
module: 2
week: 9
objectives:
  - "Load and explore climate model output using YAXArrays.jl"
  - "Work with NetCDF files and understand CMIP6 data structure"
  - "Extract and visualize climate model data for specific locations and time periods"
  - "Establish foundation for downscaling and bias correction exercises"
ps_connection: "Establishes data handling skills needed for all PS2 problems working with climate model output"

engine: julia

format:
  html:
    toc: true
    toc-depth: 2
    code-block-bg: "#f8f8f8"
    code-block-border-left: "#e1e4e5"
    theme: simplex
    number-sections: true
    fig-format: svg
  typst:
    fontsize: 11pt
    margin: 
      x: 1in
      y: 1in
    number-sections: true
    fig-format: svg

execute: 
  cache: true
  freeze: auto

# Code formatting options
code-overflow: wrap
code-line-numbers: false
code-block-font-size: "0.85em"
---

## Background

Python's xarray package has been transformative for working with labeled multi-dimensional arrays in climate science.
Originally developed at The Climate Corporation and released as open source in 2014, xarray has become the standard tool for climate data analysis in Python.
Julia has been less widely adopted in this space, but the [Climate Modeling Alliance](https://clima.caltech.edu/) is building an Earth System Model from scratch in Julia, driving development of climate data tools in the Julia ecosystem.

The Julia approach offers distinct advantages for this course.
Because Julia is fast and doesn't require switching to C, Fortran, or C++ for performance-critical code, we can implement statistical methods and algorithms in pure Julia and apply them directly to climate data.
This means you can write custom downscaling algorithms, bias correction methods, and statistical models without learning specialized library syntax or dealing with language interoperability issues.
The resulting code is often easier to understand and maintain because everything stays in one language.

xarray remains excellent and widely used in practice.
However, for this course's focus on implementing and understanding statistical downscaling methods, Julia's combination of high performance and readability makes it easier to write, test, and apply custom algorithms to real climate data.

## Objectives

1. Load and explore climate model output using YAXArrays.jl
1. Work with NetCDF files and understand CMIP6 data structure
1. Extract and visualize climate model data for specific locations and time periods

## Before

::: {.callout-important}
## Instructions

Before starting the lab, uncomment the `Pkg.instantiate()` line in the first code block and run it to install all required packages.
This will take a few minutes the first time.
After installation completes, comment the line back out to avoid reinstalling on subsequent runs.
:::

## Tasks

All packages that you need are included, and will be installed when you `instantiate` the project.

1. Work through the [Getting Started with YAXArrays.jl](https://juliadatacubes.github.io/YAXArrays.jl/dev/get_started.html) user guide and implement the examples in this lab. Note that you will need to modify the code block to use `using ...` for all packages. 
  - You can copy or paste the code blocks from the tutorial, but try to make sure you understand what each line is doing.
  - It's good practice to put all your `using` statements at the top of your code blocks. As work through more tutorials, put all the `using ...` statements together. Often, it's helpful to sort them alphabetically or in another logical order.
  - DO add brief text between code blocks -- think of this as your notes to yourself
2. A lot of the functionality of `YAXArrays.jl` comes from from [`DimensionalData.jl`](https://rafaqz.github.io/DimensionalData.jl/stable/basics). In particular, functions for selecting subsets of data, and for grouping and aggregating data are provided in `DimensionalData`.
  - Read through the [Dimensions](https://rafaqz.github.io/DimensionalData.jl/stable/dimensions), [Selectors](https://rafaqz.github.io/DimensionalData.jl/stable/selectors), and other sections of the `DimensionalData` documentation under "Getting Started"
  - Work through the `YAXArrays` [tutorial on selecting data](https://juliadatacubes.github.io/YAXArrays.jl/dev/UserGuide/select.html)
    - Pro tip: replace `path = download(url, fname)` with `if !isfile(fname); download(url, fname); end` to avoid re-downloading the file every time you run the code block
3. Working through tutorials can get repetitive, so you don't need to implement every YAXArrays user guide. However, do take a few minutes to browse through the other available guides so you're aware of what functionality exists when you need it later.
4. Work through the [Plotting Maps](https://juliadatacubes.github.io/YAXArrays.jl/dev/tutorials/plottingmaps.html) tutorial
  - Instead of `GLMakie`, we will use `CairoMakie`. You can replace `using GLMakie` and `using GLMakie.GeometryBasics` with `using CairoMakie` and `using CairoMakie.GeometryBasics`. Read more about Makie backends [here](https://docs.makie.org/dev/explanations/backends/backends)
  - Don't worry about the `AlgebraofGraphics.jl` component, although it is installed if you want to try.
5. The `store ="gs://cmip6/CMIP6/ScenarioMIP/DKRZ/MPI-ESM1-2-HR/ssp585/r1i1p1f1/3hr/tas/gn/v20190710/"` for the Plotting Maps tutorial is actually quite powerful.
  - What are we working with? Refer to the [CMIP6 Data Reference Syntax](https://pcmdi.llnl.gov/CMIP6/Guide/dataUsers.html) for more information on the file structure used
    - `cmip6`: name of the top-level Google Cloud storage bucket (hence `gs`)
    - `CMIP6`: root directory for the project
    - `ScenarioMIP`: MIP (Model Intercomparison Project) name
    - `DKRZ`: institution ID (here, the German Climate Computing Center)
    - `MPI-ESM1-2-HR`: source ID (here, the Max Planck Institute Earth System Model, version 1-2, high resolution version)
    - `ssp585`: experiment ID (here, the Shared Socioeconomic Pathway 5-8.5, a very high emissions scenario)
    - `r1i1p1f1`: variant label. `r1` is realization 1 (this would change for different ensemble members, if available). `i1` is initialization method 1. `p1` is physics version 1. `f1` is forcing index 1
    - `3hr`: time frequency (3-hourly data)
    - `tas`:  variable ID (near-surface air temperature)
    - `gn`: grid label (native grid)
    - `v20190710`: version (version date)
  - Select a single rectangular region. Compute the average `tas` over that region (if you're fancy, weight by the cosine of latitude to account for the decreasing area of grid cells towards the poles, as shown in [this xarray example](https://docs.xarray.dev/en/latest/examples/area_weighted_temperature.html)) and plot the time series of `tas` for that region.
  - Using that time series, find the hottest and coldest 3-hourly periods in the entire dataset for that region. For those two time periods, plot the spatial distribution of `tas` over the entire globe using a map projection of your choice.

Rice University members can access [this "Gem"](https://gemini.google.com/gem/1nQDNg6wH03fM1mYn5Ds7oK9qIsFOjYYN?usp=sharing) (a large language model with specific prompts) on Google Gemini.
It is designed to help you with syntax and programming challenges related to these specific packages, and to help you translate concepts from Python (e.g., xarray) to Julia.
As with all LLMs (and humans), it can be wrong.
While it probably can answer the whole lab for you, that would defeat the entire purpose of learning how to use these tools, so please use it wisely and in accordance with the course AI policy.

## Code

```{julia}
#| output: false
using Pkg
lab_dir = dirname(@__FILE__)
Pkg.activate(lab_dir)
# Pkg.instantiate() # uncomment this the first time you run the lab to install packages, then comment it back
```

Work through the Getting Started with YAXArrays.jl
```{julia}
using YAXArrays
using YAXArrays: YAXArrays as YAX

a = YAXArray(rand(2,3))

# axes or dimensions with name and tick values
axlist = (
    YAX.time(range(1, 20, length=20)),
    lon(range(1, 10, length=10)),
    lat(range(1, 5, length=15)),
    Variables(["temperature", "precipitation"])
)

# the actual data matching the dimensions defined in axlist
data = rand(20, 10, 15, 2)

# metadata about the array
props = Dict(
    "origin" => "YAXArrays.jl example",
    "x" => "longitude",
    "y" => "latitude",
);

a2 = YAXArray(axlist, data, props)

a2[Variables=At("temperature"), time=1].data
```


A lot of the functionality of YAXArrays.jl comes from from DimensionalData.jl. Read through the Dimensions, Selectors, and other sections of the DimensionalData documentation under “Getting Started”

Notes: 
- dimension can be used as wrappers for any object types
- val() to get value 
-  At(x) selector gets the index or indices exactly matching the passed in values, within ranges, or within a tolerance (atol param)!
- can select values from B with selectors from A; if not aligned, can use Near insead of At 




```{julia}
using DimensionalData
using YAXArrays
using NetCDF
using Downloads: download
using IntervalSets

if !isfile("example.nc")
  path = download("https://archive.unidata.ucar.edu/software/netcdf/examples/tos_O1_2001-2002.nc", "example.nc")
end

ds = open_dataset("example.nc")

tos = ds.tos
#positional indexing
tos[lon = 1, lat = 1]
#named indexing
tos[lon = At(1), lat = At(-79.5)]

#ranges
tos[lon = 1:10, lat = 1:10] #positional
tos[lon = At(1.0:2:19), lat = At(-79.5:1:-70.5)] #named
#tolerance
tos[lon = At(1:10; atol = 1)]

#closed interval, all points included
tos[lon = 90 .. 180] 
tos[lon = ClosedInterval(90, 180)]

#open on both ends
tos[lon = OpenInterval(90, 180)]

#interval is open on the left (excludes 90) and closed on the right (includes 180).
tos[lon =Interval{:open,:closed}(90,180)]

# Get values, .e.g., axis tick labels, of a dimension that can be used for subseting:
collect(tos.lat)
tos.lon.val
```

Work through the Plotting Maps tutorial
```{julia}
using Zarr, YAXArrays, Dates
using DimensionalData
using GLMakie, GeoMakie
using GLMakie.GeometryBasics

store ="gs://cmip6/CMIP6/ScenarioMIP/DKRZ/MPI-ESM1-2-HR/ssp585/r1i1p1f1/3hr/tas/gn/v20190710/"
g = open_dataset(zopen(store, consolidated=true))
```

```{julia}
c = g["tas"]
ct1_slice = c[time = Near(Date("2015-01-01"))]
lon_d = lookup(ct1_slice, :lon)
lat_d = lookup(ct1_slice, :lat)
data_d = ct1_slice.data[:,:]
```

Heatmap plot
```{julia}
GLMakie.activate!()

fig, ax, plt = heatmap(ct1_slice; colormap = :seaborn_icefire_gradient,
    axis = (; aspect=DataAspect()),
    figure = (; size = (800,600), fontsize=24))
fig

```
Wintri projection
```{julia}
δlon = (lon_d[2] - lon_d[1])/2
nlon = lon_d .- 180 .+ δlon
ndata = circshift(data_d, (192,1))

fig = Figure(;size=(800,600))
ax = GeoAxis(fig[1,1])
surface!(ax, nlon, lat_d, ndata; colormap = :seaborn_icefire_gradient, shading=false)
cl=lines!(ax, GeoMakie.coastlines(), color = :white, linewidth=0.85)
translate!(cl, 0, 0, 1000)
fig
```

Select a single rectangular region. Compute the average tas over that region and plot the time series of tas for that region.

```{julia}

# 1. Define remote store and the local file path for our *region*
remote_store_url = "gs://cmip6/CMIP6/ScenarioMIP/DKRZ/MPI-ESM1-2-HR/ssp585/r1i1p1f1/3hr/tas/gn/v20190710/"
local_nc_path = "tas_region.nc" # We will save our slice here as NetCDF but could use a different back end

# 2. Check if the local file exists. If not, create it.
if !isfile(local_nc_path)
    println("Local file not found. Downloading region from GCS...")
    
    tas = g["tas"]

    # Define the regional slice 
    region_remote = tas[lon = 100 .. 101, lat = 88 .. 88.5]

    # This line triggers the download and saves the result
    println("Saving region to: $local_nc_path")
    savecube(region_remote, local_nc_path, driver=:netcdf)
    
    println("Local region file created.")
else
    println("Local file $local_nc_path already exists. Skipping download.")
end

# 3. Load the regional data for analysis
println("Loading regional data from: $local_nc_path")
regional_dataset = open_dataset(local_nc_path)
regional_data = regional_dataset["tas"]

println("Regional data loaded. Shape: ", size(regional_data))
```

```{julia}
using Statistics

avg_tas = mean(skipmissing(regional_data))


println("Average TAS for the region: $avg_tas")

# Compute spatial average for each time step to create a time series
# First, let's check how many time steps we're dealing with
n_times = length(regional_data.time)
println("Number of time steps: $n_times")

#skipping time steps for computation
time_indices = 1:50:n_times
time_series = [mean(skipmissing(regional_data[time=t].data)) 
                for t in time_indices]
time_values = regional_data.time.val[time_indices]


println("Time series computed with $(length(time_series)) time steps")

# Convert from Kelvin to Celsius
time_series_celsius = time_series .- 273.15

# time_values was already set above based on whether we sampled or not
println("Time series length: ", length(time_series_celsius))
println("Temperature range (°C): ", extrema(time_series_celsius))


```

```{julia}
using CairoMakie
CairoMakie.activate!()

# Plot the time series
fig = Figure(; size = (800,600))
ax = Axis(fig[1, 1], 
    xlabel = "Time", 
    ylabel = "Temperature (°C)",
    title = "Average Temperature Time Series over rectangular region")

# Plot the time series
lines!(ax, time_values, time_series_celsius, color = :blue, linewidth = 1.5)

fig
```

Find the hottest and coldest 3-hourly periods and plot global temperature distributions
```{julia}
# Find the indices of the hottest and coldest periods
hottest_idx = argmax(time_series_celsius)
coldest_idx = argmin(time_series_celsius)

println("Hottest period: $(time_values[hottest_idx]) with temperature $(time_series_celsius[hottest_idx])°C")
println("Coldest period: $(time_values[coldest_idx]) with temperature $(time_series_celsius[coldest_idx])°C")

# Get the global temperature data for these two time periods
hottest_global = c[time = hottest_idx]
coldest_global = c[time = coldest_idx]

```

plot using wintri projection
```{julia}
using CairoMakie, GeoMakie
CairoMakie.activate!()

# Prepare data for plotting 
lon_global = lookup(hottest_global, :lon)
lat_global = lookup(hottest_global, :lat)

# Shift longitude from 0-360 to -180-180 for better map visualization
δlon = (lon_global[2] - lon_global[1])/2
nlon = lon_global .- 180 .+ δlon

# Get the temperature data and shift it correspondingly
hottest_data = circshift(hottest_global.data[:,:], (192,1))
coldest_data = circshift(coldest_global.data[:,:], (192,1))

# Convert from Kelvin to Celsius
hottest_data_celsius = hottest_data .- 273.15
coldest_data_celsius = coldest_data .- 273.15


fig = Figure(; size = (800,600))

# Plot the hottest period
ax1 = GeoAxis(fig[1,1], title = "Hottest Period: $(time_values[hottest_idx])")
surface!(ax1, nlon, lat_global, hottest_data_celsius; 
         colormap = :seaborn_icefire_gradient, shading=false,
         colorrange = extrema(hottest_data_celsius))
cl1 = lines!(ax1, GeoMakie.coastlines(), color = :white, linewidth=0.85)
translate!(cl1, 0, 0, 1000)
fig
```

```{julia}

fig = Figure(; size = (800,600))
# Plot the coldest period  
ax2 = GeoAxis(fig[1,1], title = "Coldest Period: $(time_values[coldest_idx])")
surface!(ax2, nlon, lat_global, coldest_data_celsius; 
         colormap = :seaborn_icefire_gradient, shading=false,
         colorrange = extrema(coldest_data_celsius))
cl2 = lines!(ax2, GeoMakie.coastlines(), color = :white, linewidth=0.85)
translate!(cl2, 0, 0, 1000)


fig
```





